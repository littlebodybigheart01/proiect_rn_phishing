# ğŸ“˜ README â€“ Etapa 4: Arhitectura CompletÄƒ a AplicaÈ›iei SIA bazatÄƒ pe ReÈ›ele Neuronale

**Disciplina:** ReÈ›ele Neuronale  
**InstituÈ›ie:** POLITEHNICA BucureÈ™ti â€“ FIIR  
**Student:** Chelu Fabian-Catalin  
**Grupa:** 632AB
**Link Repository GitHub:** https://github.com/littlebodybigheart01/proiect_rn_phishing 
**Data:** 05.12.2025  

---

## Scopul Etapei 4

AceastÄƒ etapÄƒ corespunde punctului **5. Dezvoltarea arhitecturii aplicaÈ›iei software bazatÄƒ pe RN** din specificaÈ›iile proiectului.

Obiectivul este livrarea unui **schelet complet È™i funcÈ›ional** al sistemului de detecÈ›ie a phishing-ului, demonstrÃ¢nd integrarea fluxului de date (Data Pipeline), a modelului de Deep Learning È™i a interfeÈ›ei cu utilizatorul. Sistemul este capabil sÄƒ parcurgÄƒ ciclul complet: Generare Date -> Antrenare -> InferenÈ›Äƒ -> AfiÈ™are Rezultat.

---

## 1. Structura Repository-ului

Proiectul respectÄƒ o structurÄƒ modularÄƒ, separÃ¢nd datele brute, codul sursÄƒ È™i modelele antrenate conform standardelor de inginerie software.

```text
â”œâ”€â”€ app.py                              # Punctul de intrare Ã®n AplicaÈ›ia Web (Streamlit)
â”œâ”€â”€ config
â”‚   â””â”€â”€ preprocessing_config.yaml       # FiÈ™ier de configurare pentru pipeline-ul de date
â”œâ”€â”€ data
â”‚   â”œâ”€â”€ processed
â”‚   â”‚   â””â”€â”€ processed_ai_generated.csv  # Date curÄƒÈ›ate È™i tokenizate (cache)
â”‚   â”œâ”€â”€ raw                             # Surse de date brute (Hibrid: Real + Sintetic)
â”‚   â”‚   â”œâ”€â”€ emailreal.csv               # Dataset Enron (EnglezÄƒ)
â”‚   â”‚   â”œâ”€â”€ smsreal.csv                 # Dataset SMS Spam Collection (EnglezÄƒ)
â”‚   â”‚   â”œâ”€â”€ phishing_ai_ro_only.csv     # Date sintetice generate cu Gemini (RomÃ¢nÄƒ)
â”‚   â”‚   â”œâ”€â”€ phishing_ai_targeted_patch.csv # Date adversariale (Hard Examples)
â”‚   â”‚   â”œâ”€â”€ multilingualdataset.csv     # Dataset intermediar
â”‚   â”‚   â””â”€â”€ final_multilingual_dataset.csv # Dataset final unificat È™i balansat
â”‚   â”œâ”€â”€ train
â”‚   â”‚   â””â”€â”€ train_ai_generated.csv      # Subset antrenament (80%)
â”‚   â”œâ”€â”€ validation
â”‚   â”‚   â””â”€â”€ validation_ai_generated.csv # Subset validare (10%)
â”‚   â””â”€â”€ test
â”‚       â””â”€â”€ test_ai_generated.csv       # Subset testare (10%)
â”œâ”€â”€ docs
â”‚   â””â”€â”€ datasets
â”‚       â””â”€â”€ plots
â”‚           â””â”€â”€ confusion_matrix.png    # Grafice de performanÈ›Äƒ
â”œâ”€â”€ models
â”‚   â””â”€â”€ phishing_distilbert_multilingual # Director salvare model antrenat
â”‚       â”œâ”€â”€ config.json
â”‚       â”œâ”€â”€ special_tokens_map.json
â”‚       â”œâ”€â”€ tf_model.h5                 # Ponderile modelului (TensorFlow)
â”‚       â”œâ”€â”€ tokenizer_config.json
â”‚       â””â”€â”€ vocab.txt
â”œâ”€â”€ README.md                           # DocumentaÈ›ia curentÄƒ
â”œâ”€â”€ requirements.txt                    # DependenÈ›e Python
â””â”€â”€ src
	â”œâ”€â”€ data_acquisition                # Modul 1: AchiziÈ›ie Date
	â”‚   â”œâ”€â”€ generate_ai_data.py         # Script generare cu Gemini API
	â”‚   â””â”€â”€ merge_all_datasets.py       # Script unificare surse hibride
	â”œâ”€â”€ neural_network                  # Modul 2: ReÈ›ea NeuronalÄƒ
	â”‚   â”œâ”€â”€ model.py                    # Definirea arhitecturii DistilBERT
	â”‚   â”œâ”€â”€ train.py                    # Bucla de antrenare
	â”‚   â”œâ”€â”€ evaluate.py                 # Script evaluare metrici
	â”‚   â””â”€â”€ predict.py                  # Script testare consolÄƒ
	â””â”€â”€ preprocessing                   # Modul Preprocesare
		â””â”€â”€ preprocess_and_split.py     # CurÄƒÈ›are, tokenizare, split
```
2. Arhitectura de Sistem (SIA)
Diagrama de mai jos (reprezentatÄƒ ca tabele pentru compatibilitate) ilustreazÄƒ fluxul datelor prin componentele sistemului, evidenÈ›iind abordarea hibridÄƒ de achiziÈ›ie a datelor È™i procesarea acestora.

**Arhitectura sistemului â€” Componenta & Flux**

| ComponentÄƒ | Rol principal | Input | Output | FiÈ™iere cheie |
|-------------|---------------|-------|--------|----------------|
| Modul 1: AchiziÈ›ie Date (Pipeline Hibrid) | Generare È™i colectare date (sintetic + real), curÄƒÈ›are, normalizare È™i balansare | Google Gemini API, seturi externe (Enron, SMS, etc.) | `final_multilingual_dataset.csv` (raw, balansat) | `src/data_acquisition/generate_ai_data.py`, `merge_all_datasets.py` |
| Modul 2: ReÈ›ea NeuronalÄƒ (DistilBERT) | Tokenizare, antrenare (fine-tuning), evaluare È™i salvare model | Dataset tokenizat (max_length=128) | Model salvat (`tf_model.h5` / SavedModel) | `src/neural_network/model.py`, `train.py`, `evaluate.py` |
| Modul 3: Web Service (Streamlit) | InterfaÈ›Äƒ utilizator, request inferenÈ›Äƒ, afiÈ™are verdict È™i explicaÈ›ii | Text introdus de utilizator | Probabilitate phishing, logits, UI update | `app.py`, `src/neural_network/predict.py` |

**Flux de date (pas cu pas)**

| Pas | Activitate | ComponentÄƒ responsabilÄƒ | CondiÈ›ie de trecere |
|-----|-----------|------------------------|---------------------|
| 1 | Generare / colectare date | `generate_ai_data.py` / surse externe | Date disponibile Ã®n `data/raw/` |
| 2 | Merge, curÄƒÈ›are, balansare | `merge_all_datasets.py` | `final_multilingual_dataset.csv` creat |
| 3 | Preprocesare & tokenizare | `preprocess_and_split.py` | Tensori pregÄƒtiÈ›i pentru antrenare/inferenÈ›Äƒ |
| 4 | Antrenare model | `train.py` | Model salvat Ã®n `models/phishing_distilbert_multilingual/` |
| 5 | InferenÈ›Äƒ Ã®n aplicaÈ›ie | `app.py` â†’ `predict.py` | RÄƒspuns (probabilitate) returnat cÄƒtre UI |



3. Descrierea Componentelor

Sistemul este modularizat pentru a asigura scalabilitatea È™i mentenabilitatea codului.

Modul 1: Data Logging / Acquisition
Acest modul gestioneazÄƒ crearea unui set de date robust. Deoarece seturile de date publice Ã®n limba romÃ¢nÄƒ pentru phishing sunt limitate, am dezvoltat o soluÈ›ie hibridÄƒ:

Generare SinteticÄƒ (generate_ai_data.py): UtilizeazÄƒ LLM-uri (Google Gemini) pentru a genera scenarii de atac specifice pieÈ›ei din RomÃ¢nia (ex: false notificÄƒri ANAF, PoÈ™ta RomÃ¢nÄƒ, BÄƒnci locale) È™i date adversariale (phishing_ai_targeted_patch.csv) pentru a corecta vulnerabilitÄƒÈ›ile modelului.

Unificare (merge_all_datasets.py): CombinÄƒ datele sintetice cu seturi reale consacrate (emailreal.csv, smsreal.csv). Scriptul gestioneazÄƒ discrepanÈ›ele de format È™i curÄƒÈ›Äƒ caracterele neconforme, rezultÃ¢nd final_multilingual_dataset.csv.

Modul 2: Neural Network (Arhitectura)
Nucleul sistemului este o reÈ›ea neuronalÄƒ bazatÄƒ pe arhitectura Transformer, utilizÃ¢nd modelul distilbert-base-multilingual-cased.

ArhitecturÄƒ: Transformer Encoder (12 straturi) + Strat Dense (Clasificare).

Input: Tokenizer DistilBERT (max_length=128).

Training: Modelul este antrenat folosind train.py, care salveazÄƒ ponderile optimizate Ã®n directorul models/phishing_distilbert_multilingual.

PerformanÈ›Äƒ: UtilizeazÄƒ funcÈ›ia de activare Sigmoid pentru a returna o probabilitate de risc Ã®ntre 0 È™i 1.

Modul 3: Web Service / UI
InterfaÈ›a (app.py) este dezvoltatÄƒ Ã®n Streamlit, oferind o experienÈ›Äƒ utilizator modernÄƒ.

Design: TemÄƒ vizualÄƒ personalizatÄƒ ("Y2K/Cyberpunk") pentru impact vizual.

FuncÈ›ionalitate: ProceseazÄƒ textul Ã®n timp real, interogheazÄƒ modelul salvat È™i afiÈ™eazÄƒ verdictul (Phishing/Legitim).

Interactivitate: Include elemente dinamice (Easter Eggs, feedback vizual instant).

4. Diagrama Fluxului de Date (State Machine)
AceastÄƒ diagramÄƒ descrie stÄƒrile prin care trece sistemul Ã®n timpul procesÄƒrii unei cereri.

**State Machine (tabele)**

**StÄƒri principale**

| Stare | Ce se Ã®ntÃ¢mplÄƒ aici | CondiÈ›ie intrare | CondiÈ›ie ieÈ™ire |
|-------|---------------------|------------------|-----------------|
| Idle | Sistemul aÈ™teaptÄƒ inputul utilizatorului | AplicaÈ›ia pornitÄƒ sau dupÄƒ un ciclu complet | Utilizator apasÄƒ "SCAN" |
| Preprocessing | CurÄƒÈ›are text, tokenizare, conversie Ã®n tensori | Text recepÈ›ionat din UI | Tensori validaÈ›i, gata pentru inferenÈ›Äƒ |
| Inference | Propagare Ã®nainte prin model (DistilBERT), calcul logits | Tensori validaÈ›i | Logits È™i scoruri calculate |
| DecisionLogic | Aplicare praguri, decizie finalÄƒ (Phishing/Legit/Uncertain) | Scoruri disponibile | Rezultat clasificat (trimis la UI) |
| UI_Update | AfiÈ™are rezultat, explicaÈ›ii È™i logare | Rezultat clasificare | Resetare la `Idle` pentru input nou |

**TranziÈ›ii critice**

| De la | CÄƒtre | CondiÈ›ie / Descriere |
|------:|:------|:--------------------|
| Idle | Preprocessing | Utilizator iniÈ›iazÄƒ scanarea (apasÄƒ "SCAN") |
| Preprocessing | Inference | Toate transformÄƒrile È™i tokenizarea s-au Ã®ncheiat cu succes (tensori validaÈ›i) |
| Inference | DecisionLogic | Modelul a returnat logits/probabilitÄƒÈ›i |
| DecisionLogic | UI_Update | Decizia finalÄƒ este calculatÄƒ (ex: scor > 0.75 â†’ Phishing) |
| UI_Update | Idle | Utilizator finalizeazÄƒ vizualizarea sau revine pentru input nou |
| DecisionLogic | PhishingState | Scor > 0.75 (exemplu de prag configurabil) |
| DecisionLogic | LegitState | Scor < 0.25 |
| DecisionLogic | UncertainState | 0.25 â‰¤ Scor â‰¤ 0.75 |
    
5. Checklist Etapa 4
General
[x] Diagrama ArhitecturÄƒ SIA creatÄƒ.

[x] Diagrama State Machine definitÄƒ È™i documentatÄƒ.

[x] Structura repository-ului este organizatÄƒ (src/, data/, models/).

Modul 1: AchiziÈ›ie Date
[x] Scripturile de generare (generate_ai_data.py) funcÈ›ioneazÄƒ corect.

[x] Scriptul de unificare (merge_all_datasets.py) integreazÄƒ date reale È™i sintetice.

[x] Dataset-ul final este salvat Ã®n data/raw/.

Modul 2: ReÈ›ea NeuronalÄƒ
[x] Modelul DistilBERT este definit Ã®n src/neural_network/model.py.

[x] Modelul este compilat È™i salvat (models/phishing_distilbert_multilingual/tf_model.h5).

[x] Scriptul de antrenare (train.py) este funcÈ›ional.

Modul 3: InterfaÈ›Äƒ Web
[x] AplicaÈ›ia app.py porneÈ™te fÄƒrÄƒ erori.

[x] InterfaÈ›a acceptÄƒ input È™i afiÈ™eazÄƒ predicÈ›ia modelului Ã®n timp real.

6. InstrucÈ›iuni de Rulare
Pentru a reproduce mediul È™i a rula aplicaÈ›ia, urmaÈ›i paÈ™ii de mai jos:

1. Instalarea DependenÈ›elor
Bash

```bash
pip install -r requirements.txt
```
2. PregÄƒtirea Datelor (OpÈ›ional)
Bash

```bash
# Unificarea datelor sintetice cu cele reale
python src/data_acquisition/merge_all_datasets.py

# Preprocesarea È™i Ã®mpÄƒrÈ›irea (Train/Val/Test)
python src/preprocessing/preprocess_and_split.py
```
3. Antrenarea Modelului
Bash

```bash
python src/neural_network/train.py
```
4. Lansarea AplicaÈ›iei Web
Bash

```bash
streamlit run app.py
```
AplicaÈ›ia va fi accesibilÄƒ la http://localhost:8501.

7. DependenÈ›e (requirements.txt)
tensorflow: Framework-ul de bazÄƒ pentru Deep Learning.

transformers: Biblioteca HuggingFace pentru modelul DistilBERT.

streamlit: Framework pentru interfaÈ›a graficÄƒ web.

google-generativeai: Clientul API pentru Google Gemini.

pandas & numpy: Manipularea datelor.

scikit-learn: Procesarea È™i Ã®mpÄƒrÈ›irea datelor.

requests: InterogÄƒri API externe. vei pune totul in readme.md (See <attachments> above for file contents. You may not need to search or read the file again.)

## Nevoi reale (Useâ€‘cases) È™i acoperirea SIA

| Nevoie realÄƒ concretÄƒ | Cum o rezolvÄƒ SIA-ul vostru | Modul software responsabil |
| :--- | :--- | :--- |
| Detectarea atacurilor de phishing localizate (ex: false notificÄƒri ANAF/Curierat Ã®n limba romÃ¢nÄƒ) care trec de filtrele clasice de spam. | Clasificare semanticÄƒ bazatÄƒ pe **DistilBERT Multilingual** â†’ verdict de risc (Phishing/Legitim) Ã®n **< 1 secundÄƒ** cu acurateÈ›e **> 98%**. | **Neural Network** + **Web Service** |
| ProtecÈ›ia utilizatorilor Ã®mpotriva Ingineriei Sociale complexe (ex: CEO Fraud fÄƒrÄƒ link-uri, Typosquatting) care pÄƒcÄƒleÈ™te ochiul uman. | Antrenare adversarialÄƒ pe dataset hibrid (Real + Sintetic generat pe scenarii specifice) â†’ identificarea tiparelor de manipulare psihologicÄƒ. | **Data Acquisition** + **Neural Network** |
| Educarea utilizatorilor privind motivele pentru care un mesaj este considerat periculos (Explainability). | Generarea automatÄƒ a unei explicaÈ›ii Ã®n limbaj natural (prin LLM) pentru fiecare verdict â†’ feedback instantaneu despre elementele suspecte detectate. | **Web Service / UI** (LogicÄƒ Backend) |

---

### 2. ContribuÈ›ia VoastrÄƒ OriginalÄƒ la Setul de Date â€“ MINIM 40% din Totalul ObservaÈ›iilor Finale

**Total observaÈ›ii finale:** ~40,000 (dupÄƒ Etapa 3 + Etapa 4)
**ObservaÈ›ii originale:** ~20,000 (~50%)

**Tipul contribuÈ›iei:**
- [x] Date generate prin simulare/metode avansate (Data Augmentation cu LLM)
- [ ] Date achiziÈ›ionate cu senzori proprii
- [ ] Etichetare/adnotare manualÄƒ
- [ ] Date sintetice prin metode avansate

**Descriere detaliatÄƒ:**
Pentru a crea un model robust È™i capabil sÄƒ detecteze atacuri specifice contextului romÃ¢nesc (care lipsesc din dataset-urile internaÈ›ionale publice precum Enron), am dezvoltat un pipeline de generare sinteticÄƒ folosind API-ul **Google Gemini**. Am creat prompt-uri specifice ("Adversarial Prompts") pentru a simula atacuri de tip:
1.  **Phishing Localizat:** Mesaje false de la instituÈ›ii romÃ¢neÈ™ti (ANAF, PoÈ™ta RomÃ¢nÄƒ, BÄƒnci: BT, ING, BCR, eMAG, OLX).
2.  **Inginerie SocialÄƒ:** CEO Fraud (fÄƒrÄƒ link-uri, bazat pe autoritate), "Prieten la nevoie".
3.  **Obfuscation:** Typosquatting (`rnicrosoft`, `Faceb00k`) È™i link-uri mascate.

Aceste date au fost apoi curÄƒÈ›ate, validate È™i combinate cu datele reale (Enron Email Corpus, SMS Spam Collection) pentru a asigura un echilibru Ã®ntre realismul limbajului natural È™i diversitatea vectorilor de atac.

**LocaÈ›ia codului:** `src/data_acquisition/generate_ai_data.py` È™i `src/data_acquisition/generate_targeted_weaknesses.py`
**LocaÈ›ia datelor:** `data/raw/phishing_ai_mixed_complete.csv` È™i `data/raw/phishing_ai_targeted_patch.csv`

**Dovezi:**
- Dataset-urile generate se aflÄƒ Ã®n directorul `data/raw/`.
- Logurile de generare È™i distribuÈ›ia claselor sunt vizibile la rularea scriptului `merge_all_datasets.py`.

